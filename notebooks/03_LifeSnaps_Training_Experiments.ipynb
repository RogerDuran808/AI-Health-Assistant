{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a0f4bdf",
   "metadata": {},
   "source": [
    "# LifeSnaps Preprocessing Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91e1a7f",
   "metadata": {},
   "source": [
    "#### Import de llibreries necessaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a140353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1832, 38)\n",
      "Shape: (458, 38)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data handling and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Imbalanced data pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# Core utilities\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Model definitions fora dels defints\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "############## IMPORTS DEL NOSTRE PAQUET ###################\n",
    "# Obtenim les funcions per entrenar i evaluar els models i registrar les mètriques\n",
    "from ai_health_assistant.utils.train_helpers import train_models, append_results, plot_learning_curve, mat_confusio, update_experiments_file\n",
    "\n",
    "# Obtenim els classificadors i els seus parametres\n",
    "from ai_health_assistant.utils.model_config import get_classifier_config, PARAM_GRIDS, CLASSIFIERS, BALANCING_METHODS\n",
    "\n",
    "# Obtenim el target, features el la construcció del preprocessador\n",
    "from ai_health_assistant.utils.prep_helpers import TARGET, build_preprocessor, FEATURES\n",
    "\n",
    "\n",
    "# Configuració de pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Carrega de dades, netes i amb fe aplicat\n",
    "df_train = pd.read_csv('../data/df_engineered_train.csv')\n",
    "df_test = pd.read_csv('../data/df_engineered_test.csv')\n",
    "    \n",
    "print(f\"Shape: {df_train.shape}\")\n",
    "print(f\"Shape: {df_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49958206",
   "metadata": {},
   "source": [
    "## Lectura de dades i split de train / test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2324f272",
   "metadata": {},
   "source": [
    "### Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fedc7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train shape: (1832, 37)\n",
      "Test shape: (458, 37)\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Distribució train:\n",
      "TIRED\n",
      "0.0    0.615721\n",
      "1.0    0.384279\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Distribució test:\n",
      "TIRED\n",
      "0.0    0.615721\n",
      "1.0    0.384279\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Col. numeriques (35): \n",
      "['bmi', 'calories', 'steps', 'lightly_active_minutes', 'moderately_active_minutes', 'very_active_minutes', 'sedentary_minutes', 'resting_hr', 'minutes_below_default_zone_1', 'minutes_in_default_zone_1', 'minutes_in_default_zone_2', 'minutes_in_default_zone_3', 'minutesAsleep', 'minutesAwake', 'sleep_efficiency', 'sleep_deep_ratio', 'sleep_light_ratio', 'sleep_rem_ratio', 'sleep_wake_ratio', 'daily_temperature_variation', 'rmssd', 'spo2', 'full_sleep_breathing_rate', 'wake_after_sleep_pct', 'steps_norm_cal', 'deep_sleep_score', 'active_sedentary_ratio', 'sleep_activity_balance', 'bmi_hr_interaction', 'sleep_quality_index', 'hr_zone_variability', 'recovery_factor', 'sleep_eff_rmssd', 'active_to_rest_transition', 'active_to_total_ratio']\n",
      "Col. categoriques (2): \n",
      "['age', 'gender']\n"
     ]
    }
   ],
   "source": [
    "# Fem l'split de les dades, separant les features i el target\n",
    "X_train = df_train.drop(columns=[TARGET])\n",
    "y_train = df_train[TARGET]\n",
    "\n",
    "X_test = df_test.drop(columns=[TARGET])\n",
    "y_test = df_test[TARGET]\n",
    "\n",
    "print(f\"\\nTrain shape: {X_train.shape}\")\n",
    "print(f\"Test shape: {X_test.shape}\")\n",
    "print('\\n','--'*50)\n",
    "print(f\"\\nDistribució train:\\n{y_train.value_counts(normalize=True)}\")\n",
    "print(f\"\\nDistribució test:\\n{y_test.value_counts(normalize=True)}\")\n",
    "\n",
    "numerical_features = X_train.select_dtypes(include=['number']).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(exclude=['number']).columns.tolist()\n",
    "\n",
    "print(f\"\\nCol. numeriques ({len(numerical_features)}): \\n{numerical_features}\")\n",
    "print(f\"Col. categoriques ({len(categorical_features)}): \\n{categorical_features}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45316505",
   "metadata": {},
   "source": [
    "### Definim el preprocessador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b09ee13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = build_preprocessor(df_train, FEATURES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddc26fc",
   "metadata": {},
   "source": [
    "## ENTRENAMENT DEL MODEL BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7533c0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_cols = ['Experiment', 'Train F1 (1)', 'Train F1 (macro global)','Train Accuracy', 'Test Recall (1)', 'Test Precision (1)', 'Test F1 (1)', 'Test F1 (macro global)','Test Accuracy']\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Filtre de selecció dels models a entrenar\n",
    "PROVA_MODELS = [\"BalancedRandomForest\", \"LGBM\"]\n",
    "# Selecció del mètode de balanceig\n",
    "balance_name = \"SMOTETomek\"\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "# Filtre per no haver de entrenar tots el models\n",
    "CLASSIFIERS_FILTER = {k: v for k, v in CLASSIFIERS.items() if k in PROVA_MODELS}\n",
    "balance_method = BALANCING_METHODS[balance_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732d822b",
   "metadata": {},
   "source": [
    "### Regressió Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "220e35df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenant model...\n",
      "\n",
      "Train F1 (1): 0.5156 | Test F1 (1): 0.4800 | Train Acc: 0.5939 | Test Acc: 0.5742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6680    0.6135    0.6396       282\n",
      "         1.0     0.4523    0.5114    0.4800       176\n",
      "\n",
      "    accuracy                         0.5742       458\n",
      "   macro avg     0.5601    0.5624    0.5598       458\n",
      "weighted avg     0.5851    0.5742    0.5782       458\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Train F1 (1)</th>\n",
       "      <th>Train F1 (macro global)</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Recall (1)</th>\n",
       "      <th>Test Precision (1)</th>\n",
       "      <th>Test F1 (1)</th>\n",
       "      <th>Test F1 (macro global)</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression_EntrenamentBasic</td>\n",
       "      <td>0.51562</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.59389</td>\n",
       "      <td>0.51136</td>\n",
       "      <td>0.45226</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.55978</td>\n",
       "      <td>0.57424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Experiment  Train F1 (1)  Train F1 (macro global)  \\\n",
       "0  LogisticRegression_EntrenamentBasic       0.51562                    0.583   \n",
       "\n",
       "   Train Accuracy  Test Recall (1)  Test Precision (1)  Test F1 (1)  \\\n",
       "0         0.59389          0.51136             0.45226         0.48   \n",
       "\n",
       "   Test F1 (macro global)  Test Accuracy  \n",
       "0                 0.55978        0.57424  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Métriques guardades a ../results/02_experiments/experiments.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reg_results = []\n",
    "reg_models = {}\n",
    "\n",
    "reg_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", LogisticRegression(\n",
    "        max_iter=2000,            # convergència assegurada\n",
    "        class_weight=\"balanced\", # tracta l’imbalance de la classe 1\n",
    "        solver=\"lbfgs\",          # ràpid i estable per datasets petits/mitjans\n",
    "    ))\n",
    "])\n",
    "\n",
    "reg_param_grid = {\n",
    "    \"classifier__C\": [0.001, 0.01, 0.1, 1, 10, 100, 200, 500, 1000]\n",
    "}\n",
    "\n",
    "best_est, y_train_pred, train_report, y_test_pred, test_report, best_params, best_score = train_models(\n",
    "        X_train, \n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test, \n",
    "        reg_pipeline, \n",
    "        reg_param_grid,\n",
    "        search_type='grid',\n",
    "    )\n",
    "\n",
    "reg_results_df = append_results(\n",
    "    reg_results,\n",
    "    \"LogisticRegression\",\n",
    "    train_report,\n",
    "    test_report,\n",
    "    best_params,\n",
    "    best_score,\n",
    "    experiment=\"EntrenamentBasic\"\n",
    ")\n",
    "\n",
    "# update_experiments_file(reg_results_df)\n",
    "display(reg_results_df[display_cols])\n",
    "update_experiments_file(reg_results_df)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7716717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== BalancedRandomForest ====\n",
      "Entrenant model...\n",
      "\n",
      "Train F1 (1): 0.7136 | Test F1 (1): 0.5793 | Train Acc: 0.6960 | Test Acc: 0.5306\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7724    0.3369    0.4691       282\n",
      "         1.0     0.4418    0.8409    0.5793       176\n",
      "\n",
      "    accuracy                         0.5306       458\n",
      "   macro avg     0.6071    0.5889    0.5242       458\n",
      "weighted avg     0.6453    0.5306    0.5115       458\n",
      "\n",
      "\n",
      "==== LGBM ====\n",
      "Entrenant model...\n",
      "\n",
      "Train F1 (1): 0.8812 | Test F1 (1): 0.5736 | Train Acc: 0.9023 | Test Acc: 0.6266\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7382    0.6099    0.6680       282\n",
      "         1.0     0.5111    0.6534    0.5736       176\n",
      "\n",
      "    accuracy                         0.6266       458\n",
      "   macro avg     0.6247    0.6317    0.6208       458\n",
      "weighted avg     0.6509    0.6266    0.6317       458\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_results = []\n",
    "\n",
    "for model, classifier in CLASSIFIERS_FILTER.items():\n",
    "\n",
    "    if model == \"BalancedRandomForest\":\n",
    "        pipeline = ImbPipeline([\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"classifier\", classifier)\n",
    "        ])\n",
    "    else:\n",
    "        pipeline = ImbPipeline([\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"balance\", balance_method),\n",
    "            (\"classifier\", classifier)\n",
    "        ])\n",
    "\n",
    "    print(f\"\\n==== {model} ====\")\n",
    "    best_est, y_train_pred, train_report, y_test_pred, test_report, best_params, best_score = train_models(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test, \n",
    "        pipeline,\n",
    "        PARAM_GRIDS[model]\n",
    "    )\n",
    "\n",
    "    base_results_df = append_results(\n",
    "    base_results,\n",
    "    model,\n",
    "    train_report,\n",
    "    test_report,\n",
    "    best_params,\n",
    "    best_score,\n",
    "    experiment=\"Entrenament basic\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d13c45c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Métriques guardades a ../results/02_experiments/experiments.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "update_experiments_file(base_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71d30d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__n_estimators': 1163, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 3, 'classifier__max_features': 'log2', 'classifier__max_depth': 8, 'classifier__class_weight': 'balanced'}\n"
     ]
    }
   ],
   "source": [
    "print(base_results_df[base_results_df['Model'] == \"BalancedRandomForest\"]['Best Params'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d77e13f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# El model que vulguem inspecciona\n",
    "model_name = \"LGBM\" # RandomForest, MLP, GradientBoosting, SVM\n",
    "csf = base_models[model_name]\n",
    "\n",
    "\n",
    "# Visualització del train\n",
    "y_train_pred = csf.predict(X_train)\n",
    "\n",
    "mat_confusio(\n",
    "    f'Entrenament basic {model_name} (Train)',\n",
    "    y_train,\n",
    "    y_train_pred\n",
    ")\n",
    "\n",
    "# Visualització del test\n",
    "y_test_pred = csf.predict(X_test)\n",
    "\n",
    "mat_confusio(\n",
    "    f\"Entrenament basic {model_name} (Test)\",\n",
    "    y_test,\n",
    "    y_test_pred\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe9ba4d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Observem la corba d'aprenentatge:\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mplot_learning_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_models\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\src\\ai_health_assistant\\utils\\train_helpers.py:172\u001b[39m, in \u001b[36mplot_learning_curve\u001b[39m\u001b[34m(model_name, best_est, X, y, save, score)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m score == \u001b[33m'\u001b[39m\u001b[33mf1\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    170\u001b[39m     score = make_scorer(f1_score, pos_label=\u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m train_sizes, train_scores, val_scores = \u001b[43mlearning_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbest_est\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinspace\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\n\u001b[32m    179\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m train_mean = train_scores.mean(axis=\u001b[32m1\u001b[39m)\n\u001b[32m    181\u001b[39m val_mean   = val_scores.mean(axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:2085\u001b[39m, in \u001b[36mlearning_curve\u001b[39m\u001b[34m(estimator, X, y, groups, train_sizes, cv, scoring, exploit_incremental_learning, n_jobs, pre_dispatch, verbose, shuffle, random_state, error_score, return_times, fit_params, params)\u001b[39m\n\u001b[32m   2082\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m n_train_samples \u001b[38;5;129;01min\u001b[39;00m train_sizes_abs:\n\u001b[32m   2083\u001b[39m         train_test_proportions.append((train[:n_train_samples], test))\n\u001b[32m-> \u001b[39m\u001b[32m2085\u001b[39m results = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2086\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2087\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2088\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2089\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2090\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2091\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2092\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2093\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2094\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2095\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2096\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2097\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2098\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2099\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2100\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2101\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_test_proportions\u001b[49m\n\u001b[32m   2102\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2103\u001b[39m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[32m   2104\u001b[39m results = _aggregate_score_dicts(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\joblib\\parallel.py:2071\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2065\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2071\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1681\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1678\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1680\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1681\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1683\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1684\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1799\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1789\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1794\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1797\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1798\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1799\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1800\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1802\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1803\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1810\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Observem la corba d'aprenentatge:\n",
    "\n",
    "plot_learning_curve(\n",
    "    model_name,\n",
    "    base_models[model_name],\n",
    "    X_train,\n",
    "    y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215ba5fe",
   "metadata": {},
   "source": [
    "## EXPERIMENT 1: Importancia de les caracteristiques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c94399",
   "metadata": {},
   "source": [
    "Entrenem RandomForest per indentificar les caracteristiques més importants (10-15), posteriorment entrenem els models utilitzant aquestes 10-15 característiques, per veure si augmenta el rendiment del model. Proavarem tambe amb permutation importances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29a22c5",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56753310",
   "metadata": {},
   "source": [
    "La Gini importance d’una feature és: La suma de totes les reduccions d’impuresa (Gini) que ha causat al llarg de tots els arbres i de totes les seves aparicions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa629838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train F1 (1): 0.7136 | Test F1 (1): 0.5793 | Train Acc: 0.6960 | Test Acc: 0.5306\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7724    0.3369    0.4691       282\n",
      "         1.0     0.4418    0.8409    0.5793       176\n",
      "\n",
      "    accuracy                         0.5306       458\n",
      "   macro avg     0.6071    0.5889    0.5242       458\n",
      "weighted avg     0.6453    0.5306    0.5115       458\n",
      "\n",
      "Top-10 features: ['num__calories', 'num__bmi_hr_interaction', 'num__bmi', 'num__resting_hr', 'num__steps_norm_cal', 'num__daily_temperature_variation', 'num__recovery_factor', 'num__hr_zone_variability', 'num__lightly_active_minutes', 'num__minutesAsleep']\n",
      "Top-15 features: ['num__calories', 'num__bmi_hr_interaction', 'num__bmi', 'num__resting_hr', 'num__steps_norm_cal', 'num__daily_temperature_variation', 'num__recovery_factor', 'num__hr_zone_variability', 'num__lightly_active_minutes', 'num__minutesAsleep', 'num__active_to_total_ratio', 'num__sedentary_minutes', 'num__minutes_below_default_zone_1', 'num__minutes_in_default_zone_1', 'num__steps']\n"
     ]
    }
   ],
   "source": [
    "# Param grid & pipeline bàsic de random forest\n",
    "rf_name = \"BalancedRandomForest\"\n",
    "\n",
    "pipeline = ImbPipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", CLASSIFIERS[rf_name])\n",
    "])\n",
    "\n",
    "# Entrenament del model\n",
    "best_est, y_train_pred, train_report, y_test_pred, test_report, best_params, best_score = train_models(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test, \n",
    "    pipeline, \n",
    "    PARAM_GRIDS[rf_name],\n",
    "    search_type='grid'\n",
    ")\n",
    "preprocessor = best_est.named_steps['preprocessor']\n",
    "\n",
    "if hasattr(preprocessor, 'get_feature_names_out'):\n",
    "    feature_names = preprocessor.get_feature_names_out()\n",
    "else:\n",
    "    # If using older scikit-learn, you might need to handle this differently\n",
    "    numeric_features = X_train.select_dtypes(include=['number']).columns\n",
    "    categorical_features = X_train.select_dtypes(exclude=['number']).columns\n",
    "    \n",
    "    numeric_transformer = preprocessor.named_transformers_['num']\n",
    "    if hasattr(numeric_transformer, 'get_feature_names_out'):\n",
    "        numeric_feature_names = numeric_transformer.get_feature_names_out(numeric_features)\n",
    "    else:\n",
    "        numeric_feature_names = numeric_features\n",
    "        \n",
    "    categorical_transformer = preprocessor.named_transformers_['cat']\n",
    "    if hasattr(categorical_transformer, 'get_feature_names_out'):\n",
    "        categorical_feature_names = categorical_transformer.get_feature_names_out(categorical_features)\n",
    "    else:\n",
    "        # For one-hot encoded features\n",
    "        ohe = categorical_transformer.named_steps['onehot']\n",
    "        categorical_feature_names = ohe.get_feature_names_out(categorical_features)\n",
    "    \n",
    "    feature_names = list(numeric_feature_names) + list(categorical_feature_names)\n",
    "\n",
    "# Now create the Series with the correct feature names\n",
    "importances_raw = pd.Series(\n",
    "    best_est.named_steps[\"classifier\"].feature_importances_,\n",
    "    index=feature_names\n",
    ")\n",
    "\n",
    "def base_name(feat):\n",
    "    if feat.startswith(\"cat__\") and \"_\" in feat[6:]:\n",
    "        return feat.rsplit(\"_\", 1)[0]\n",
    "    return feat\n",
    "\n",
    "agg_importances = (\n",
    "    importances_raw.groupby(base_name).sum().sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "# Top-10 i Top-15 importàncies\n",
    "\n",
    "top10 = agg_importances.head(10).index.tolist()\n",
    "top15 = agg_importances.head(15).index.tolist()\n",
    "print(\"Top-10 features:\", top10)\n",
    "print(\"Top-15 features:\", top15)\n",
    "\n",
    "# Visualització de les Top-15 importàncies\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(top15, agg_importances.head(15).values)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"Top-15 Gini Importances\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Importància (Gini)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b476077",
   "metadata": {},
   "source": [
    "### Rentrenament de models 10-15 millors features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c860cb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenament models amb Top10\n",
      "==== BalancedRandomForest ====\n",
      "\n",
      "Train F1 (1): 0.7546 | Test F1 (1): 0.4888 | Train Acc: 0.8051 | Test Acc: 0.6026\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6799    0.6702    0.6750       282\n",
      "         1.0     0.4833    0.4943    0.4888       176\n",
      "\n",
      "    accuracy                         0.6026       458\n",
      "   macro avg     0.5816    0.5823    0.5819       458\n",
      "weighted avg     0.6043    0.6026    0.6034       458\n",
      "\n",
      "==== LGBM ====\n",
      "\n",
      "Train F1 (1): 0.8374 | Test F1 (1): 0.5425 | Train Acc: 0.8597 | Test Acc: 0.5764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7095    0.5284    0.6057       282\n",
      "         1.0     0.4637    0.6534    0.5425       176\n",
      "\n",
      "    accuracy                         0.5764       458\n",
      "   macro avg     0.5866    0.5909    0.5741       458\n",
      "weighted avg     0.6151    0.5764    0.5814       458\n",
      "\n",
      "\n",
      "Entrenament models amb Top15\n",
      "==== BalancedRandomForest ====\n",
      "\n",
      "Train F1 (1): 0.7810 | Test F1 (1): 0.4903 | Train Acc: 0.8242 | Test Acc: 0.6004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6800    0.6631    0.6715       282\n",
      "         1.0     0.4809    0.5000    0.4903       176\n",
      "\n",
      "    accuracy                         0.6004       458\n",
      "   macro avg     0.5804    0.5816    0.5809       458\n",
      "weighted avg     0.6035    0.6004    0.6018       458\n",
      "\n",
      "==== LGBM ====\n",
      "\n",
      "Train F1 (1): 0.8561 | Test F1 (1): 0.5318 | Train Acc: 0.8766 | Test Acc: 0.5655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6986    0.5177    0.5947       282\n",
      "         1.0     0.4538    0.6420    0.5318       176\n",
      "\n",
      "    accuracy                         0.5655       458\n",
      "   macro avg     0.5762    0.5799    0.5632       458\n",
      "weighted avg     0.6045    0.5655    0.5705       458\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definim els dos conjunts de features\n",
    "feature_sets = {\n",
    "    \"Top10\": top10,   # llista de 10 noms de feature “base”\n",
    "    \"Top15\": top15    # llista de 15 noms de feature “base”\n",
    "}\n",
    "\n",
    "# Reentrenament i avaluació per a cada subset\n",
    "fi_results = []\n",
    "fi_models = {}\n",
    "\n",
    "numerical_features = X_train.select_dtypes(include=['number']).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(exclude=['number']).columns.tolist()\n",
    "\n",
    "preprocessor = build_preprocessor(X_train)\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# Get the feature names after transformation\n",
    "if hasattr(preprocessor, 'get_feature_names_out'):\n",
    "    feature_names = preprocessor.get_feature_names_out()\n",
    "else:\n",
    "    # For older scikit-learn versions\n",
    "    numeric_features = X_train.select_dtypes(include=['number']).columns\n",
    "    categorical_features = X_train.select_dtypes(include=['object', 'category']).columns\n",
    "    numeric_feature_names = list(numeric_features)\n",
    "    categorical_feature_names = list(categorical_features)\n",
    "    feature_names = numeric_feature_names + categorical_feature_names\n",
    "\n",
    "# Convert to DataFrame with proper column names\n",
    "X_train_transformed = pd.DataFrame(X_train_transformed, columns=feature_names, index=X_train.index)\n",
    "X_test_transformed = pd.DataFrame(X_test_transformed, columns=feature_names, index=X_test.index)\n",
    "\n",
    "\n",
    "for label, feats in feature_sets.items():\n",
    "    print(f\"\\nEntrenament models amb {label}\")\n",
    "    num_feats = [f for f in feats if f in numerical_features]\n",
    "    cat_feats = [f for f in feats if f in categorical_features]\n",
    "\n",
    "    for model, classifier in CLASSIFIERS_FILTER.items():\n",
    "\n",
    "        print(f'==== {model} ====')\n",
    "        pipe = ImbPipeline([\n",
    "            (\"balance\", balance_method),\n",
    "            (\"classifier\", classifier)\n",
    "        ])\n",
    "\n",
    "\n",
    "        best_est, y_train_pred, train_report, y_test_pred, test_report, best_params, best_score = train_models(\n",
    "            X_train_transformed[feats],\n",
    "            y_train,\n",
    "            X_test_transformed[feats],\n",
    "            y_test,\n",
    "            pipe,\n",
    "            PARAM_GRIDS[model]\n",
    "        )\n",
    "\n",
    "        fi_models[f\"{model}_{label}\"] = best_est\n",
    "\n",
    "        append_results(\n",
    "            fi_results,\n",
    "            model,\n",
    "            train_report,\n",
    "            test_report,\n",
    "            best_params,\n",
    "            best_score,\n",
    "            experiment=f\"FI_{label}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee2bbfc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Model</th>\n",
       "      <th>Train F1 (1)</th>\n",
       "      <th>Test F1 (1)</th>\n",
       "      <th>Train F1 (macro global)</th>\n",
       "      <th>Test F1 (macro global)</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TIRED</td>\n",
       "      <td>FI_Top10</td>\n",
       "      <td>BalancedRandomForest</td>\n",
       "      <td>0.7546</td>\n",
       "      <td>0.4888</td>\n",
       "      <td>0.7965</td>\n",
       "      <td>0.5819</td>\n",
       "      <td>0.8051</td>\n",
       "      <td>0.6026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TIRED</td>\n",
       "      <td>FI_Top10</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.8374</td>\n",
       "      <td>0.5425</td>\n",
       "      <td>0.8570</td>\n",
       "      <td>0.5741</td>\n",
       "      <td>0.8597</td>\n",
       "      <td>0.5764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TIRED</td>\n",
       "      <td>FI_Top15</td>\n",
       "      <td>BalancedRandomForest</td>\n",
       "      <td>0.7810</td>\n",
       "      <td>0.4903</td>\n",
       "      <td>0.8171</td>\n",
       "      <td>0.5809</td>\n",
       "      <td>0.8242</td>\n",
       "      <td>0.6004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TIRED</td>\n",
       "      <td>FI_Top15</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.8561</td>\n",
       "      <td>0.5318</td>\n",
       "      <td>0.8741</td>\n",
       "      <td>0.5632</td>\n",
       "      <td>0.8766</td>\n",
       "      <td>0.5655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Target Experiment                 Model  Train F1 (1)  Test F1 (1)  \\\n",
       "0  TIRED   FI_Top10  BalancedRandomForest        0.7546       0.4888   \n",
       "1  TIRED   FI_Top10                  LGBM        0.8374       0.5425   \n",
       "2  TIRED   FI_Top15  BalancedRandomForest        0.7810       0.4903   \n",
       "3  TIRED   FI_Top15                  LGBM        0.8561       0.5318   \n",
       "\n",
       "   Train F1 (macro global)  Test F1 (macro global)  Train Accuracy  \\\n",
       "0                   0.7965                  0.5819          0.8051   \n",
       "1                   0.8570                  0.5741          0.8597   \n",
       "2                   0.8171                  0.5809          0.8242   \n",
       "3                   0.8741                  0.5632          0.8766   \n",
       "\n",
       "   Test Accuracy  \n",
       "0         0.6026  \n",
       "1         0.5764  \n",
       "2         0.6004  \n",
       "3         0.5655  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance_results_df = pd.DataFrame(fi_results)\n",
    "\n",
    "display(feature_importance_results_df[display_cols].round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab945b58",
   "metadata": {},
   "source": [
    "### Permutation Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cc9aaf",
   "metadata": {},
   "source": [
    "Per avaluar la importància de les característiques del model. Serveix per determinar quines característiques tenen més impacte en el rendiment del model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a7e161f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train F1 (1): 0.8037 | Test F1 (1): 0.4900 | Train Acc: 0.8499 | Test Acc: 0.6092\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6820    0.6844    0.6832       282\n",
      "         1.0     0.4914    0.4886    0.4900       176\n",
      "\n",
      "    accuracy                         0.6092       458\n",
      "   macro avg     0.5867    0.5865    0.5866       458\n",
      "weighted avg     0.6088    0.6092    0.6090       458\n",
      "\n",
      "\n",
      "Top-15 features (Permutation):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>num__bmi</th>\n",
       "      <td>0.031998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num__daily_temperature_variation</th>\n",
       "      <td>0.013526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat__age_&lt;30</th>\n",
       "      <td>0.008373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num__minutesAwake</th>\n",
       "      <td>0.006648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num__sleep_efficiency</th>\n",
       "      <td>0.005273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num__sleep_quality_index</th>\n",
       "      <td>0.004258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num__sleep_deep_ratio</th>\n",
       "      <td>0.003908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num__deep_sleep_score</th>\n",
       "      <td>0.003570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num__rmssd</th>\n",
       "      <td>0.003483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num__sleep_wake_ratio</th>\n",
       "      <td>0.002871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num__sleep_eff_rmssd</th>\n",
       "      <td>0.002096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat__gender_MALE</th>\n",
       "      <td>0.001441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat__age_&gt;=30</th>\n",
       "      <td>0.001419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat__gender_FEMALE</th>\n",
       "      <td>0.000633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num__moderately_active_minutes</th>\n",
       "      <td>0.000491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Importancia\n",
       "num__bmi                             0.031998\n",
       "num__daily_temperature_variation     0.013526\n",
       "cat__age_<30                         0.008373\n",
       "num__minutesAwake                    0.006648\n",
       "num__sleep_efficiency                0.005273\n",
       "num__sleep_quality_index             0.004258\n",
       "num__sleep_deep_ratio                0.003908\n",
       "num__deep_sleep_score                0.003570\n",
       "num__rmssd                           0.003483\n",
       "num__sleep_wake_ratio                0.002871\n",
       "num__sleep_eff_rmssd                 0.002096\n",
       "cat__gender_MALE                     0.001441\n",
       "cat__age_>=30                        0.001419\n",
       "cat__gender_FEMALE                   0.000633\n",
       "num__moderately_active_minutes       0.000491"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train the random forest model\n",
    "rf_name = 'RandomForest'\n",
    "clf_rf, param_grid_rf = get_classifier_config(rf_name)\n",
    "\n",
    "# Create a new pipeline that includes the preprocessor\n",
    "pipe = ImbPipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"balance\", balance_method),\n",
    "    (\"classifier\", clf_rf)\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "best_est, y_train_pred, train_report, y_test_pred, test_report, best_params, best_score = train_models( \n",
    "    X_train, \n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test, \n",
    "    pipe, \n",
    "    param_grid_rf,\n",
    "    search_type='grid'\n",
    ")\n",
    "\n",
    "best_rf_model = best_est\n",
    "\n",
    "# To calculate permutation importance, we need to:\n",
    "# 1. Get the preprocessor and classifier from the pipeline\n",
    "preprocessor = best_rf_model.named_steps['preprocessor']\n",
    "classifier = best_rf_model.named_steps['classifier']\n",
    "\n",
    "# 2. Transform the test data using the preprocessor\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# 3. Get feature names after transformation\n",
    "if hasattr(preprocessor, 'get_feature_names_out'):\n",
    "    feature_names = preprocessor.get_feature_names_out()\n",
    "else:\n",
    "    # Fallback for older scikit-learn versions\n",
    "    numeric_features = X_train.select_dtypes(include=['number']).columns\n",
    "    categorical_features = X_train.select_dtypes(include=['object', 'category']).columns\n",
    "    \n",
    "    # Get numeric feature names\n",
    "    numeric_transformer = preprocessor.named_transformers_['num']\n",
    "    if hasattr(numeric_transformer, 'get_feature_names_out'):\n",
    "        numeric_feature_names = numeric_transformer.get_feature_names_out(numeric_features)\n",
    "    else:\n",
    "        numeric_feature_names = list(numeric_features)\n",
    "    \n",
    "    # Get categorical feature names\n",
    "    categorical_transformer = preprocessor.named_transformers_['cat']\n",
    "    if hasattr(categorical_transformer, 'get_feature_names_out'):\n",
    "        categorical_feature_names = categorical_transformer.get_feature_names_out(categorical_features)\n",
    "    else:\n",
    "        ohe = categorical_transformer.named_steps['onehot']\n",
    "        categorical_feature_names = ohe.get_feature_names_out(categorical_features)\n",
    "    \n",
    "    feature_names = list(numeric_feature_names) + list(categorical_feature_names)\n",
    "\n",
    "# 4. Create a new pipeline with just the classifier for permutation importance\n",
    "# (since we've already preprocessed the data)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Create a simple pipeline with just the classifier\n",
    "final_estimator = Pipeline([\n",
    "    ('classifier', classifier)\n",
    "])\n",
    "\n",
    "# 5. Calculate permutation importance using the transformed data\n",
    "result = permutation_importance(\n",
    "    final_estimator,\n",
    "    X_test_transformed, \n",
    "    y_test,\n",
    "    n_repeats=200,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 6. Create Series with feature names\n",
    "perm_importances = pd.Series(\n",
    "    result.importances_mean, \n",
    "    index=feature_names\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "# Extract Top-10 and Top-15 features\n",
    "perm_top_features = {\n",
    "    10: perm_importances.head(10).index.tolist(),\n",
    "    15: perm_importances.head(15).index.tolist()\n",
    "}\n",
    "\n",
    "# Display the top 15 features\n",
    "print(\"\\nTop-15 features (Permutation):\")\n",
    "display(perm_importances.head(15).to_frame(\"Importancia\"))\n",
    "\n",
    "# Plot the top 15 features\n",
    "plt.figure(figsize=(12, 6))\n",
    "top15 = perm_importances.head(15)\n",
    "bars = plt.barh(top15.index, top15.values)\n",
    "plt.title(\"Top-15 Permutation Importance\", fontsize=14)\n",
    "plt.xlabel(\"Mean Decrease in F1 Score\", fontsize=12)\n",
    "plt.gca().invert_yaxis()  # Most important features on top\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "\n",
    "# Add value labels on the bars\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    plt.text(width + 0.001, bar.get_y() + bar.get_height()/2., \n",
    "             f'{width:.3f}', \n",
    "             ha='left', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca388e9",
   "metadata": {},
   "source": [
    "### Reentrenament Permutation importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb52b21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns in X_train: ['age', 'gender', 'bmi', 'calories', 'steps', 'lightly_active_minutes', 'moderately_active_minutes', 'very_active_minutes', 'sedentary_minutes', 'resting_hr', 'minutes_below_default_zone_1', 'minutes_in_default_zone_1', 'minutes_in_default_zone_2', 'minutes_in_default_zone_3', 'minutesAsleep', 'minutesAwake', 'sleep_efficiency', 'sleep_deep_ratio', 'sleep_light_ratio', 'sleep_rem_ratio', 'sleep_wake_ratio', 'daily_temperature_variation', 'rmssd', 'spo2', 'full_sleep_breathing_rate', 'wake_after_sleep_pct', 'steps_norm_cal', 'deep_sleep_score', 'active_sedentary_ratio', 'sleep_activity_balance', 'bmi_hr_interaction', 'sleep_quality_index', 'hr_zone_variability', 'recovery_factor', 'sleep_eff_rmssd', 'active_to_rest_transition', 'active_to_total_ratio']\n",
      "\n",
      "Trying to select features: ['num__bmi', 'num__daily_temperature_variation', 'cat__age_<30', 'num__minutesAwake', 'num__sleep_efficiency', 'num__sleep_quality_index', 'num__sleep_deep_ratio', 'num__deep_sleep_score', 'num__rmssd', 'num__sleep_wake_ratio']\n",
      "\n",
      "Mapped features: ['sleep_quality_index', 'rmssd', 'sleep_wake_ratio', 'sleep_deep_ratio', 'daily_temperature_variation', 'deep_sleep_score', 'bmi', 'sleep_efficiency', 'minutesAwake']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"d:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3805, in get_loc\n    return self._engine.get_loc(casted_key)\n           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n  File \"index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n  File \"index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\\\_libs\\\\hashtable_class_helper.pxi\", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas\\\\_libs\\\\hashtable_class_helper.pxi\", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'calories'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"d:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 364, in _get_column_indices\n    col_idx = all_columns.get_loc(col)\n  File \"d:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3812, in get_loc\n    raise KeyError(key) from err\nKeyError: 'calories'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"d:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"d:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\imblearn\\pipeline.py\", line 518, in fit\n    Xt, yt = self._fit(X, y, routed_params, raw_params=params)\n             ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\imblearn\\pipeline.py\", line 430, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ~~~~~~~~~~~~~~~~~~~~~~~~^\n        cloned_transformer,\n        ^^^^^^^^^^^^^^^^^^^\n    ...<5 lines>...\n        params=step_params,\n        ^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"d:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\joblib\\memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"d:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\imblearn\\pipeline.py\", line 1383, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"d:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 319, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"d:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"d:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 993, in fit_transform\n    self._validate_column_callables(X)\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n  File \"d:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 552, in _validate_column_callables\n    transformer_to_input_indices[name] = _get_column_indices(X, columns)\n                                         ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n  File \"d:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 372, in _get_column_indices\n    raise ValueError(\"A given column is not a column of the dataframe\") from e\nValueError: A given column is not a column of the dataframe\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model, classifier \u001b[38;5;129;01min\u001b[39;00m CLASSIFIERS_FILTER.items():\n\u001b[32m     44\u001b[39m     pipe = ImbPipeline([\n\u001b[32m     45\u001b[39m         (\u001b[33m\"\u001b[39m\u001b[33mpreprocessor\u001b[39m\u001b[33m\"\u001b[39m, preprocessor),\n\u001b[32m     46\u001b[39m         (\u001b[33m\"\u001b[39m\u001b[33mbalance\u001b[39m\u001b[33m\"\u001b[39m, balance_method),\n\u001b[32m     47\u001b[39m         (\u001b[33m\"\u001b[39m\u001b[33mclassifier\u001b[39m\u001b[33m\"\u001b[39m, classifier)\n\u001b[32m     48\u001b[39m     ])\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     best_est, y_train_pred, train_report, y_test_pred, test_report, best_params, best_score = \u001b[43mtrain_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX_train_sel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX_test_sel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m        \u001b[49m\u001b[43mPARAM_GRIDS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m     perm_models[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_Top\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m] = best_est\n\u001b[32m     61\u001b[39m     append_results(\n\u001b[32m     62\u001b[39m         perm_results,\n\u001b[32m     63\u001b[39m         model,\n\u001b[32m   (...)\u001b[39m\u001b[32m     69\u001b[39m         experiment=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPerm_Top\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     70\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\src\\ai_health_assistant\\utils\\train_helpers.py:65\u001b[39m, in \u001b[36mtrain_models\u001b[39m\u001b[34m(X_train, y_train, X_test, y_test, pipeline, param_grid, scoring, cv, n_iter, search_type)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     search = RandomizedSearchCV(\n\u001b[32m     55\u001b[39m         estimator=pipeline,\n\u001b[32m     56\u001b[39m         param_distributions=param_grid,\n\u001b[32m   (...)\u001b[39m\u001b[32m     62\u001b[39m         refit=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     63\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[43msearch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# Millor estimador\u001b[39;00m\n\u001b[32m     68\u001b[39m best_est = search.best_estimator_\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1951\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1950\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1951\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1952\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1953\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   1954\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1955\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1001\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    994\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) != n_candidates * n_splits:\n\u001b[32m    995\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    996\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcv.split and cv.get_n_splits returned \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    997\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    998\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(n_splits, \u001b[38;5;28mlen\u001b[39m(out) // n_candidates)\n\u001b[32m    999\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1001\u001b[39m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[32m   1004\u001b[39m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[32m   1005\u001b[39m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[32m   1006\u001b[39m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[32m   1007\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.scoring):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:517\u001b[39m, in \u001b[36m_warn_or_raise_about_fit_failures\u001b[39m\u001b[34m(results, error_score)\u001b[39m\n\u001b[32m    510\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits == num_fits:\n\u001b[32m    511\u001b[39m     all_fits_failed_message = (\n\u001b[32m    512\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    513\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    514\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou can try to debug the error by setting error_score=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    516\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    520\u001b[39m     some_fits_failed_message = (\n\u001b[32m    521\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    522\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe score on these train-test partitions for these parameters\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    526\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    527\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"d:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3805, in get_loc\n    return self._engine.get_loc(casted_key)\n           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n  File \"index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n  File \"index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\\\_libs\\\\hashtable_class_helper.pxi\", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas\\\\_libs\\\\hashtable_class_helper.pxi\", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'calories'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"d:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 364, in _get_column_indices\n    col_idx = all_columns.get_loc(col)\n  File \"d:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3812, in get_loc\n    raise KeyError(key) from err\nKeyError: 'calories'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"d:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"d:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\imblearn\\pipeline.py\", line 518, in fit\n    Xt, yt = self._fit(X, y, routed_params, raw_params=params)\n             ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\imblearn\\pipeline.py\", line 430, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ~~~~~~~~~~~~~~~~~~~~~~~~^\n        cloned_transformer,\n        ^^^^^^^^^^^^^^^^^^^\n    ...<5 lines>...\n        params=step_params,\n        ^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"d:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\joblib\\memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"d:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\imblearn\\pipeline.py\", line 1383, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"d:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 319, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"d:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"d:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 993, in fit_transform\n    self._validate_column_callables(X)\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n  File \"d:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 552, in _validate_column_callables\n    transformer_to_input_indices[name] = _get_column_indices(X, columns)\n                                         ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n  File \"d:\\OneDrive\\Documentos\\02. Formació\\2. UNIVERSITAT\\05. TFG\\02. Code\\AI-Health-Assistant\\.venv\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 372, in _get_column_indices\n    raise ValueError(\"A given column is not a column of the dataframe\") from e\nValueError: A given column is not a column of the dataframe\n"
     ]
    }
   ],
   "source": [
    "# First, let's see what features we actually have\n",
    "print(\"Available columns in X_train:\", X_train.columns.tolist())\n",
    "print(\"\\nTrying to select features:\", sel_feats)\n",
    "\n",
    "# The issue is that sel_feats contains transformed feature names (with num__ and cat__ prefixes)\n",
    "# but X_train has the original feature names. We need to map between them.\n",
    "\n",
    "# Create a mapping from transformed names to original names\n",
    "# This depends on how your preprocessor is set up\n",
    "original_features = X_train.columns.tolist()\n",
    "\n",
    "# If you're using a ColumnTransformer, you can get the feature names like this:\n",
    "if hasattr(preprocessor, 'get_feature_names_out'):\n",
    "    transformed_features = preprocessor.get_feature_names_out()\n",
    "    # Create a mapping from transformed to original names\n",
    "    # This is a simple mapping - adjust based on your actual transformation\n",
    "    feature_mapping = {}\n",
    "    for orig in original_features:\n",
    "        for trans in transformed_features:\n",
    "            if orig in trans:  # Simple check - might need more sophisticated mapping\n",
    "                feature_mapping[trans] = orig\n",
    "                break\n",
    "    \n",
    "    # Now map the selected features back to original names\n",
    "    original_sel_feats = []\n",
    "    for feat in sel_feats:\n",
    "        # Remove the prefix (num__ or cat__) to get the base name\n",
    "        base_name = feat.split('__', 1)[-1] if '__' in feat else feat\n",
    "        # Find the original feature that matches this base name\n",
    "        for orig in original_features:\n",
    "            if base_name in orig:\n",
    "                original_sel_feats.append(orig)\n",
    "                break\n",
    "    original_sel_feats = list(set(original_sel_feats))  # Remove duplicates\n",
    "    \n",
    "    print(\"\\nMapped features:\", original_sel_feats)\n",
    "    \n",
    "    # Now use these original feature names for selection\n",
    "    X_train_sel = X_train[original_sel_feats]\n",
    "    X_test_sel = X_test[original_sel_feats]\n",
    "    \n",
    "    # Now train the models with the selected features\n",
    "    for model, classifier in CLASSIFIERS_FILTER.items():\n",
    "        pipe = ImbPipeline([\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"balance\", balance_method),\n",
    "            (\"classifier\", classifier)\n",
    "        ])\n",
    "\n",
    "        best_est, y_train_pred, train_report, y_test_pred, test_report, best_params, best_score = train_models( \n",
    "            X_train_sel, \n",
    "            y_train,\n",
    "            X_test_sel,\n",
    "            y_test, \n",
    "            pipe, \n",
    "            PARAM_GRIDS[model]\n",
    "        )\n",
    "\n",
    "        perm_models[f'{model}_Top{k}'] = best_est\n",
    "\n",
    "        append_results(\n",
    "            perm_results,\n",
    "            model,\n",
    "            best_params,\n",
    "            y_train,\n",
    "            y_train_pred,\n",
    "            y_test,\n",
    "            y_test_pred,\n",
    "            experiment=f\"Perm_Top{k}\"\n",
    "        )\n",
    "else:\n",
    "    print(\"Could not get feature names from preprocessor. Please check your preprocessor setup.\")\n",
    "    # Fallback: Use the original features that match any of the selected feature names\n",
    "    original_sel_feats = [f for f in original_features if any(sf.split('__')[-1] in f for sf in sel_feats)]\n",
    "    print(\"Trying with features:\", original_sel_feats)\n",
    "    \n",
    "    if original_sel_feats:\n",
    "        X_train_sel = X_train[original_sel_feats]\n",
    "        X_test_sel = X_test[original_sel_feats]\n",
    "        \n",
    "        # Rest of the training code as above\n",
    "        # ...\n",
    "    else:\n",
    "        print(\"No matching features found. Please check your feature names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "067f10ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Model</th>\n",
       "      <th>Train F1 (1)</th>\n",
       "      <th>Test F1 (1)</th>\n",
       "      <th>Train F1 (macro global)</th>\n",
       "      <th>Test F1 (macro global)</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TIRED</td>\n",
       "      <td>Perm_Top10</td>\n",
       "      <td>BalancedRandomForest</td>\n",
       "      <td>0.7398</td>\n",
       "      <td>0.5893</td>\n",
       "      <td>0.7981</td>\n",
       "      <td>0.6850</td>\n",
       "      <td>0.8150</td>\n",
       "      <td>0.7140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TIRED</td>\n",
       "      <td>Perm_Top10</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>0.6054</td>\n",
       "      <td>0.9508</td>\n",
       "      <td>0.6690</td>\n",
       "      <td>0.9531</td>\n",
       "      <td>0.6812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TIRED</td>\n",
       "      <td>Perm_Top15</td>\n",
       "      <td>BalancedRandomForest</td>\n",
       "      <td>0.7985</td>\n",
       "      <td>0.6272</td>\n",
       "      <td>0.8388</td>\n",
       "      <td>0.7046</td>\n",
       "      <td>0.8488</td>\n",
       "      <td>0.7249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TIRED</td>\n",
       "      <td>Perm_Top15</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.6207</td>\n",
       "      <td>0.9566</td>\n",
       "      <td>0.6777</td>\n",
       "      <td>0.9585</td>\n",
       "      <td>0.6878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Target  Experiment                 Model  Train F1 (1)  Test F1 (1)  \\\n",
       "0  TIRED  Perm_Top10  BalancedRandomForest        0.7398       0.5893   \n",
       "1  TIRED  Perm_Top10                  LGBM        0.9403       0.6054   \n",
       "2  TIRED  Perm_Top15  BalancedRandomForest        0.7985       0.6272   \n",
       "3  TIRED  Perm_Top15                  LGBM        0.9474       0.6207   \n",
       "\n",
       "   Train F1 (macro global)  Test F1 (macro global)  Train Accuracy  \\\n",
       "0                   0.7981                  0.6850          0.8150   \n",
       "1                   0.9508                  0.6690          0.9531   \n",
       "2                   0.8388                  0.7046          0.8488   \n",
       "3                   0.9566                  0.6777          0.9585   \n",
       "\n",
       "   Test Accuracy  \n",
       "0         0.7140  \n",
       "1         0.6812  \n",
       "2         0.7249  \n",
       "3         0.6878  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perm_topk_results_df = pd.DataFrame(perm_results)\n",
    "display(perm_topk_results_df[display_cols].round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c085d9",
   "metadata": {},
   "source": [
    "## EXPERIMENT 2: PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8849b34",
   "metadata": {},
   "source": [
    "Es realitza una anàlisi de components principals (PCA) per examinar com evolucionen els components més rellevants del conjunt de dades en termes de variància explicada acumulada, considerant els primers 5, 10, 15, 20 i 25 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f14c20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(random_state=42)\n",
    "pca.fit(X_train)\n",
    "\n",
    "# 3) Calcular la varianza explicada acumulada\n",
    "explained_cumsum = pca.explained_variance_ratio_.cumsum()*100\n",
    "\n",
    "# 4) Definir los puntos de interés y extraer sus valores\n",
    "ks = [5, 10, 15, 20, 25]\n",
    "cums = explained_cumsum[[k-1 for k in ks]]\n",
    "\n",
    "# 5) Dibujar la curva completa y señalar los ks elegidos\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(\n",
    "    range(1, len(explained_cumsum) + 1),\n",
    "    explained_cumsum,\n",
    ")\n",
    "plt.scatter(ks, cums)\n",
    "plt.xlabel('Número de componentes')\n",
    "plt.ylabel('Varianza explicada acumulada')\n",
    "plt.title('Evolución de la varianza explicada según n_components')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f5ef062",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components_list = [5, 10, 15, 20, 25]\n",
    "for k in n_components_list:\n",
    "    # Ajusta PCA\n",
    "    pca = PCA(n_components=k, random_state=42)\n",
    "    pca.fit(X_train)\n",
    "\n",
    "    # loadings: matriz (n_features, k)\n",
    "    loadings = pca.components_.T\n",
    "\n",
    "    # importancia = suma de cargas absolutes de cada feature en tots els components\n",
    "    importance = np.sum(np.abs(loadings), axis=1)\n",
    "\n",
    "    # crea DataFrame, ordena top-k\n",
    "    df_imp = pd.DataFrame({\n",
    "        'feature':    all_features,\n",
    "        'importance': importance\n",
    "    }).sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "    topk = df_imp.head(k)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.barh(topk['feature'][::-1], topk['importance'][::-1])\n",
    "    plt.xlabel('Importancia (suma de |carregues|)')\n",
    "    plt.title(f'Top {k} features segons PCA')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b8467b",
   "metadata": {},
   "source": [
    "Aquests gràfics mostren, per cada valor de *k* (5, 10, 15, 20 i 25 components), quines variables original s’aporten més a l’espai de la PCA i, per tant, expliquen més variància del conjunt de dades.\n",
    "\n",
    "* **Components principals**: són noves variables creades com a combinacions lineals de les variables originals.\n",
    "* **Càrregues (loadings)**: cada component té un coeficient per a cada variable; aquell coeficient indica quant “pesa” la variable en aquest eix.\n",
    "* **Importància de la variable**: per a cada variable, sumem el valor absolut de les càrregues als primers *k* components. Una suma més alta vol dir que la variable contribueix de manera rellevant a la variació capturada per aquests *k* eixos.\n",
    "\n",
    "Així podem veure quines són les *k* variables que més pesen ens diu quins atributs són més informatius (i quins, en canvi, aporten informació redundant).\n",
    "Els tops *k* ajuden a identificar les característiques més representatives del dataset segons la PCA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14564904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- PCA - 5 components --\n",
      "\n",
      "Train F1 (1): 0.7491 | Test F1 (1): 0.4985 | Train Acc: 0.8160 | Test Acc: 0.6354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6910    0.7376    0.7136       282\n",
      "         1.0     0.5287    0.4716    0.4985       176\n",
      "\n",
      "    accuracy                         0.6354       458\n",
      "   macro avg     0.6098    0.6046    0.6060       458\n",
      "weighted avg     0.6286    0.6354    0.6309       458\n",
      "\n",
      "\n",
      "Train F1 (1): 0.7073 | Test F1 (1): 0.5000 | Train Acc: 0.7118 | Test Acc: 0.4629\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6268    0.3156    0.4198       282\n",
      "         1.0     0.3892    0.6989    0.5000       176\n",
      "\n",
      "    accuracy                         0.4629       458\n",
      "   macro avg     0.5080    0.5072    0.4599       458\n",
      "weighted avg     0.5355    0.4629    0.4506       458\n",
      "\n",
      "\n",
      "-- PCA - 10 components --\n",
      "\n",
      "Train F1 (1): 0.8208 | Test F1 (1): 0.5784 | Train Acc: 0.8608 | Test Acc: 0.6594\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7386    0.6915    0.7143       282\n",
      "         1.0     0.5515    0.6080    0.5784       176\n",
      "\n",
      "    accuracy                         0.6594       458\n",
      "   macro avg     0.6451    0.6497    0.6463       458\n",
      "weighted avg     0.6667    0.6594    0.6621       458\n",
      "\n",
      "\n",
      "Train F1 (1): 0.9439 | Test F1 (1): 0.5411 | Train Acc: 0.9558 | Test Acc: 0.5852\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7091    0.5532    0.6215       282\n",
      "         1.0     0.4706    0.6364    0.5411       176\n",
      "\n",
      "    accuracy                         0.5852       458\n",
      "   macro avg     0.5898    0.5948    0.5813       458\n",
      "weighted avg     0.6174    0.5852    0.5906       458\n",
      "\n",
      "\n",
      "-- PCA - 15 components --\n",
      "\n",
      "Train F1 (1): 0.8614 | Test F1 (1): 0.5225 | Train Acc: 0.8925 | Test Acc: 0.6288\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7014    0.6915    0.6964       282\n",
      "         1.0     0.5167    0.5284    0.5225       176\n",
      "\n",
      "    accuracy                         0.6288       458\n",
      "   macro avg     0.6091    0.6099    0.6095       458\n",
      "weighted avg     0.6304    0.6288    0.6296       458\n",
      "\n",
      "\n",
      "Train F1 (1): 0.9448 | Test F1 (1): 0.5558 | Train Acc: 0.9563 | Test Acc: 0.6092\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7229    0.5922    0.6511       282\n",
      "         1.0     0.4934    0.6364    0.5558       176\n",
      "\n",
      "    accuracy                         0.6092       458\n",
      "   macro avg     0.6082    0.6143    0.6035       458\n",
      "weighted avg     0.6347    0.6092    0.6145       458\n",
      "\n",
      "\n",
      "-- PCA - 20 components --\n",
      "\n",
      "Train F1 (1): 0.8947 | Test F1 (1): 0.5242 | Train Acc: 0.9192 | Test Acc: 0.6354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7032    0.7057    0.7044       282\n",
      "         1.0     0.5257    0.5227    0.5242       176\n",
      "\n",
      "    accuracy                         0.6354       458\n",
      "   macro avg     0.6144    0.6142    0.6143       458\n",
      "weighted avg     0.6350    0.6354    0.6352       458\n",
      "\n",
      "\n",
      "Train F1 (1): 0.9464 | Test F1 (1): 0.5547 | Train Acc: 0.9580 | Test Acc: 0.6354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7220    0.6631    0.6913       282\n",
      "         1.0     0.5226    0.5909    0.5547       176\n",
      "\n",
      "    accuracy                         0.6354       458\n",
      "   macro avg     0.6223    0.6270    0.6230       458\n",
      "weighted avg     0.6454    0.6354    0.6388       458\n",
      "\n",
      "\n",
      "-- PCA - 25 components --\n",
      "\n",
      "Train F1 (1): 0.9022 | Test F1 (1): 0.5665 | Train Acc: 0.9252 | Test Acc: 0.6725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7292    0.7447    0.7368       282\n",
      "         1.0     0.5765    0.5568    0.5665       176\n",
      "\n",
      "    accuracy                         0.6725       458\n",
      "   macro avg     0.6528    0.6507    0.6517       458\n",
      "weighted avg     0.6705    0.6725    0.6714       458\n",
      "\n",
      "\n",
      "Train F1 (1): 0.9488 | Test F1 (1): 0.5489 | Train Acc: 0.9602 | Test Acc: 0.6376\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7180    0.6773    0.6971       282\n",
      "         1.0     0.5260    0.5739    0.5489       176\n",
      "\n",
      "    accuracy                         0.6376       458\n",
      "   macro avg     0.6220    0.6256    0.6230       458\n",
      "weighted avg     0.6443    0.6376    0.6401       458\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Guarda resultats i models\n",
    "pca_results = []\n",
    "pca_models = {}\n",
    "\n",
    "\n",
    "for k in n_components_list:\n",
    "    print(f\"\\n-- PCA - {k} components --\")\n",
    "\n",
    "    for model, classifier in CLASSIFIERS_FILTER.items():\n",
    "        # Pipeline amb preprocessor, SMOTE, PCA i classificador\n",
    "        pipeline = ImbPipeline([\n",
    "            (\"balance\",       balance_method),\n",
    "            (\"pca\",          PCA(n_components=k, random_state=42)),\n",
    "            (\"classifier\",   classifier)\n",
    "        ])\n",
    "\n",
    "        best_est, y_pred, report, best_params, best_score, best_params, best_score = train_models( \n",
    "        X_train, \n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        pipeline, \n",
    "        PARAM_GRIDS[model],\n",
    "        search_type=\"grid\"\n",
    "        )\n",
    "\n",
    "        # Guarda el millor model\n",
    "        pca_models[f'{model}_PCA{k}'] = best_est\n",
    "\n",
    "        df_pca_results = append_results(\n",
    "            pca_results,\n",
    "            model,\n",
    "            train_report,\n",
    "            test_report,\n",
    "            best_params,\n",
    "            best_score,\n",
    "            experiment=f\"PCA_{k}\",\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4b76e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Model</th>\n",
       "      <th>Train F1 (1)</th>\n",
       "      <th>Test F1 (1)</th>\n",
       "      <th>Train F1 (macro global)</th>\n",
       "      <th>Test F1 (macro global)</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TIRED</td>\n",
       "      <td>PCA_5</td>\n",
       "      <td>BalancedRandomForest</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.6207</td>\n",
       "      <td>0.9566</td>\n",
       "      <td>0.6777</td>\n",
       "      <td>0.9585</td>\n",
       "      <td>0.6878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TIRED</td>\n",
       "      <td>PCA_5</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.6207</td>\n",
       "      <td>0.9566</td>\n",
       "      <td>0.6777</td>\n",
       "      <td>0.9585</td>\n",
       "      <td>0.6878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TIRED</td>\n",
       "      <td>PCA_10</td>\n",
       "      <td>BalancedRandomForest</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.6207</td>\n",
       "      <td>0.9566</td>\n",
       "      <td>0.6777</td>\n",
       "      <td>0.9585</td>\n",
       "      <td>0.6878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TIRED</td>\n",
       "      <td>PCA_10</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.6207</td>\n",
       "      <td>0.9566</td>\n",
       "      <td>0.6777</td>\n",
       "      <td>0.9585</td>\n",
       "      <td>0.6878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TIRED</td>\n",
       "      <td>PCA_15</td>\n",
       "      <td>BalancedRandomForest</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.6207</td>\n",
       "      <td>0.9566</td>\n",
       "      <td>0.6777</td>\n",
       "      <td>0.9585</td>\n",
       "      <td>0.6878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TIRED</td>\n",
       "      <td>PCA_15</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.6207</td>\n",
       "      <td>0.9566</td>\n",
       "      <td>0.6777</td>\n",
       "      <td>0.9585</td>\n",
       "      <td>0.6878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TIRED</td>\n",
       "      <td>PCA_20</td>\n",
       "      <td>BalancedRandomForest</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.6207</td>\n",
       "      <td>0.9566</td>\n",
       "      <td>0.6777</td>\n",
       "      <td>0.9585</td>\n",
       "      <td>0.6878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TIRED</td>\n",
       "      <td>PCA_20</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.6207</td>\n",
       "      <td>0.9566</td>\n",
       "      <td>0.6777</td>\n",
       "      <td>0.9585</td>\n",
       "      <td>0.6878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TIRED</td>\n",
       "      <td>PCA_25</td>\n",
       "      <td>BalancedRandomForest</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.6207</td>\n",
       "      <td>0.9566</td>\n",
       "      <td>0.6777</td>\n",
       "      <td>0.9585</td>\n",
       "      <td>0.6878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TIRED</td>\n",
       "      <td>PCA_25</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.6207</td>\n",
       "      <td>0.9566</td>\n",
       "      <td>0.6777</td>\n",
       "      <td>0.9585</td>\n",
       "      <td>0.6878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Target Experiment                 Model  Train F1 (1)  Test F1 (1)  \\\n",
       "0  TIRED      PCA_5  BalancedRandomForest        0.9474       0.6207   \n",
       "1  TIRED      PCA_5                  LGBM        0.9474       0.6207   \n",
       "2  TIRED     PCA_10  BalancedRandomForest        0.9474       0.6207   \n",
       "3  TIRED     PCA_10                  LGBM        0.9474       0.6207   \n",
       "4  TIRED     PCA_15  BalancedRandomForest        0.9474       0.6207   \n",
       "5  TIRED     PCA_15                  LGBM        0.9474       0.6207   \n",
       "6  TIRED     PCA_20  BalancedRandomForest        0.9474       0.6207   \n",
       "7  TIRED     PCA_20                  LGBM        0.9474       0.6207   \n",
       "8  TIRED     PCA_25  BalancedRandomForest        0.9474       0.6207   \n",
       "9  TIRED     PCA_25                  LGBM        0.9474       0.6207   \n",
       "\n",
       "   Train F1 (macro global)  Test F1 (macro global)  Train Accuracy  \\\n",
       "0                   0.9566                  0.6777          0.9585   \n",
       "1                   0.9566                  0.6777          0.9585   \n",
       "2                   0.9566                  0.6777          0.9585   \n",
       "3                   0.9566                  0.6777          0.9585   \n",
       "4                   0.9566                  0.6777          0.9585   \n",
       "5                   0.9566                  0.6777          0.9585   \n",
       "6                   0.9566                  0.6777          0.9585   \n",
       "7                   0.9566                  0.6777          0.9585   \n",
       "8                   0.9566                  0.6777          0.9585   \n",
       "9                   0.9566                  0.6777          0.9585   \n",
       "\n",
       "   Test Accuracy  \n",
       "0         0.6878  \n",
       "1         0.6878  \n",
       "2         0.6878  \n",
       "3         0.6878  \n",
       "4         0.6878  \n",
       "5         0.6878  \n",
       "6         0.6878  \n",
       "7         0.6878  \n",
       "8         0.6878  \n",
       "9         0.6878  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca_results_df = pd.DataFrame(pca_results)\n",
    "display(pca_results_df[display_cols].round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acd681e",
   "metadata": {},
   "source": [
    "## Anàlisi de resultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d292891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combined results from all experiments.\n",
      "\n",
      "--- Overall Performance Analysis (Sorted by Test F1-Macro) ---\n",
      "\n",
      "--- Target: TIRED ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Model</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test F1 (1)</th>\n",
       "      <th>Test F1 (macro global)</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TIRED</td>\n",
       "      <td>Entrenament basic</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.7314</td>\n",
       "      <td>0.6516</td>\n",
       "      <td>0.7165</td>\n",
       "      <td>{'classifier__subsample': 0.7590327755184709, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TIRED</td>\n",
       "      <td>Entrenament basic</td>\n",
       "      <td>BalancedRandomForest</td>\n",
       "      <td>0.7249</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.7039</td>\n",
       "      <td>{'classifier__n_estimators': 1163, 'classifier...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TIRED</td>\n",
       "      <td>Perm_Top15</td>\n",
       "      <td>BalancedRandomForest</td>\n",
       "      <td>0.7249</td>\n",
       "      <td>0.6272</td>\n",
       "      <td>0.7046</td>\n",
       "      <td>{'classifier__n_estimators': 1163, 'classifier...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TIRED</td>\n",
       "      <td>FI_Top15</td>\n",
       "      <td>BalancedRandomForest</td>\n",
       "      <td>0.7227</td>\n",
       "      <td>0.5968</td>\n",
       "      <td>0.6928</td>\n",
       "      <td>{'classifier__n_estimators': 1163, 'classifier...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TIRED</td>\n",
       "      <td>FI_Top10</td>\n",
       "      <td>BalancedRandomForest</td>\n",
       "      <td>0.7162</td>\n",
       "      <td>0.5667</td>\n",
       "      <td>0.6778</td>\n",
       "      <td>{'classifier__n_estimators': 1163, 'classifier...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Target         Experiment                 Model  Test Accuracy  Test F1 (1)  \\\n",
       "0  TIRED  Entrenament basic                  LGBM         0.7314       0.6516   \n",
       "1  TIRED  Entrenament basic  BalancedRandomForest         0.7249       0.6250   \n",
       "2  TIRED         Perm_Top15  BalancedRandomForest         0.7249       0.6272   \n",
       "3  TIRED           FI_Top15  BalancedRandomForest         0.7227       0.5968   \n",
       "4  TIRED           FI_Top10  BalancedRandomForest         0.7162       0.5667   \n",
       "\n",
       "   Test F1 (macro global)                                        Best Params  \n",
       "0                  0.7165  {'classifier__subsample': 0.7590327755184709, ...  \n",
       "1                  0.7039  {'classifier__n_estimators': 1163, 'classifier...  \n",
       "2                  0.7046  {'classifier__n_estimators': 1163, 'classifier...  \n",
       "3                  0.6928  {'classifier__n_estimators': 1163, 'classifier...  \n",
       "4                  0.6778  {'classifier__n_estimators': 1163, 'classifier...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Results Compilation ---\n",
    "all_results_dfs = [base_results_df]\n",
    "if 'feature_importance_results_df' in locals() and not feature_importance_results_df.empty: \n",
    "    all_results_dfs.append(feature_importance_results_df)\n",
    "\n",
    "if 'perm_topk_results_df' in locals() and not perm_topk_results_df.empty: \n",
    "    all_results_dfs.append(perm_topk_results_df)\n",
    "\n",
    "if 'pca_results_df' in locals() and not pca_results_df.empty: \n",
    "    all_results_dfs.append(pca_results_df)\n",
    "\n",
    "if len(all_results_dfs) > 1:\n",
    "    combined_results_df = pd.concat(all_results_dfs, ignore_index=True)\n",
    "    print(\"\\nCombined results from all experiments.\")\n",
    "else:\n",
    "    print(\"\\nOnly baseline results available.\")\n",
    "    combined_results_df = base_results_df\n",
    "\n",
    "final_cols = [\"Target\", \"Experiment\", \"Model\", \"Test Accuracy\",\"Test F1 (1)\", \"Test F1 (macro global)\",\"Best Params\"]\n",
    " \n",
    "combined_results_df = combined_results_df[final_cols]\n",
    "\n",
    "# --- Analysis ---\n",
    "print(\"\\n--- Overall Performance Analysis (Sorted by Test F1-Macro) ---\")\n",
    "combined_results_sorted = combined_results_df.sort_values(by=[\"Test Accuracy\"], ascending=[False]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(f\"\\n--- Target: {TARGET} ---\")\n",
    "display(combined_results_sorted[final_cols].head().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca32b6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 models per a TIRED segons Test Accuracy:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test F1 (1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.731441</td>\n",
       "      <td>0.651558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BalancedRandomForest</td>\n",
       "      <td>0.724891</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BalancedRandomForest</td>\n",
       "      <td>0.724891</td>\n",
       "      <td>0.627219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BalancedRandomForest</td>\n",
       "      <td>0.722707</td>\n",
       "      <td>0.596825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BalancedRandomForest</td>\n",
       "      <td>0.716157</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Test Accuracy  Test F1 (1)\n",
       "0                  LGBM       0.731441     0.651558\n",
       "1  BalancedRandomForest       0.724891     0.625000\n",
       "2  BalancedRandomForest       0.724891     0.627219\n",
       "3  BalancedRandomForest       0.722707     0.596825\n",
       "4  BalancedRandomForest       0.716157     0.566667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tired_top5 = combined_results_sorted.head(5)\n",
    "\n",
    "# Mostra la taula resum dels 5 millors\n",
    "print(f\"\\nTop 5 models per a {TARGET} segons Test Accuracy:\\n\")\n",
    "display(tired_top5[[\"Model\",\"Test Accuracy\",\"Test F1 (1)\"]])\n",
    "\n",
    "# Dibuixa la matriu de confusió de cada un\n",
    "for model in tired_top5[\"Model\"]:\n",
    "    clf = base_models[model] \n",
    "    y_pred = clf.predict(X_test)  \n",
    "    cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1])\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(f\"Confusion Matrix — {TARGET} — {model}\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
